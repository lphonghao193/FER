{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1351797,"sourceType":"datasetVersion","datasetId":786787}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\nfrom sklearn.metrics import confusion_matrix , classification_report \nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\n\nfrom IPython.display import clear_output\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization, Input, LeakyReLU","metadata":{"trusted":true,"execution":{"iopub.status.idle":"2025-03-07T10:24:33.168381Z","shell.execute_reply.started":"2025-03-07T10:24:16.258495Z","shell.execute_reply":"2025-03-07T10:24:33.167580Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import tensorflow as tf\ntf.config.set_visible_devices(tf.config.experimental.list_physical_devices('GPU'), 'GPU')\nprint(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dir = \"/kaggle/input/fer2013/train\"\ntest_dir = \"/kaggle/input/fer2013/test\"\n\nSEED = 12\nIMG_HEIGHT = 48\nIMG_WIDTH = 48\nBATCH_SIZE = 256\nEPOCHS = 20\nFINE_TUNING_EPOCHS = 15\nAUTOTUNE = tf.data.AUTOTUNE\nLR = 0.01\nNUM_CLASSES = 7\nEARLY_STOPPING_CRITERIA=3\nCLASS_LABELS  = ['Anger', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sadness', \"Surprise\"]\nCLASS_LABELS_EMOJIS = [\"üëø\", \"ü§¢\" , \"üò±\" , \"üòä\" , \"üòê \", \"üòî\" , \"üò≤\" ]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preprocess_fun = tf.keras.applications.densenet.preprocess_input\n\ntrain_datagen = ImageDataGenerator(horizontal_flip=True,\n                                   width_shift_range=0.1,\n                                   height_shift_range=0.05,\n                                   rescale = 1./255,\n                                   validation_split = 0.2,\n                                   preprocessing_function=preprocess_fun\n                                  )\n\ntest_datagen = ImageDataGenerator(rescale = 1./255,\n                                  validation_split = 0.2,\n                                  preprocessing_function=preprocess_fun)\n\ntrain_generator = train_datagen.flow_from_directory(directory = train_dir,\n                                                    target_size = (IMG_HEIGHT ,IMG_WIDTH),\n                                                    batch_size = BATCH_SIZE,\n                                                    shuffle  = True , \n                                                    color_mode = \"rgb\",\n                                                    class_mode = \"categorical\",\n                                                    subset = \"training\",\n                                                    seed = 12\n                                                   )\n\nvalidation_generator = test_datagen.flow_from_directory(directory = train_dir,\n                                                         target_size = (IMG_HEIGHT ,IMG_WIDTH),\n                                                         batch_size = BATCH_SIZE,\n                                                         shuffle  = True , \n                                                         color_mode = \"rgb\",\n                                                         class_mode = \"categorical\",\n                                                         subset = \"validation\",\n                                                         seed = 12\n                                                        )\n\ntest_generator = test_datagen.flow_from_directory(directory = test_dir,\n                                                   target_size = (IMG_HEIGHT ,IMG_WIDTH),\n                                                    batch_size = BATCH_SIZE,\n                                                    shuffle  = False , \n                                                    color_mode = \"rgb\",\n                                                    class_mode = \"categorical\",\n                                                    seed = 12\n                                                  )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Helper Functions\ndef display_one_image(image, title, subplot, color):\n    plt.subplot(subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    plt.title(title, fontsize=16)\n    \ndef display_nine_images(images, titles, title_colors=None):\n    subplot = 331\n    plt.figure(figsize=(13,13))\n    for i in range(9):\n        color = 'black' if title_colors is None else title_colors[i]\n        display_one_image(images[i], titles[i], 331+i, color)\n    plt.tight_layout()\n    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n    plt.show()\n\ndef image_title(label, prediction):\n  # Both prediction (probabilities) and label (one-hot) are arrays with one item per class.\n    class_idx = np.argmax(label, axis=-1)\n    prediction_idx = np.argmax(prediction, axis=-1)\n    if class_idx == prediction_idx:\n        return f'{CLASS_LABELS[prediction_idx]} [correct]', 'black'\n    else:\n        return f'{CLASS_LABELS[prediction_idx]} [incorrect, should be {CLASS_LABELS[class_idx]}]', 'red'\n\ndef get_titles(images, labels, model):\n    predictions = model.predict(images)\n    titles, colors = [], []\n    for label, prediction in zip(classes, predictions):\n        title, color = image_title(label, prediction)\n        titles.append(title)\n        colors.append(color)\n    return titles, colors\n\nimg_datagen = ImageDataGenerator(rescale = 1./255)\nimg_generator = img_datagen.flow_from_directory(directory = train_dir,\n                                                   target_size = (IMG_HEIGHT ,IMG_WIDTH),\n                                                    batch_size = BATCH_SIZE,\n                                                    shuffle  = True , \n                                                    color_mode = \"rgb\",\n                                                    class_mode = \"categorical\",\n                                                    seed = 12\n                                                  )\nclear_output()\n\nimages, classes = next(img_generator)\nclass_idxs = np.argmax(classes, axis=-1) \nlabels = [CLASS_LABELS[idx] for idx in class_idxs]\ndisplay_nine_images(images, labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model= keras.models.Sequential()\nmodel.add(Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3)))\n# model.add(Conv2D(32, kernel_size=(3, 3), padding='same'))\n# model.add(LeakyReLU(alpha=0.01))\nmodel.add(Conv2D(32,(3,3), padding='same'))\nmodel.add(Conv2D(32,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.01))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64,(3,3), padding='same'))\nmodel.add(Conv2D(64,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.01))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n    \nmodel.add(Conv2D(64,(3,3), padding='same'))\nmodel.add(Conv2D(64,(3,3), padding='same'))\nmodel.add(Conv2D(64,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.01))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128,(3,3), padding='same'))\nmodel.add(Conv2D(128,(3,3), padding='same'))\nmodel.add(Conv2D(128,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.01))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten()) \nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.01))\nmodel.add(Dropout(0.25))\n    \nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha=0.01))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(7, activation='softmax'))\n    \nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = LR), \n            loss='categorical_crossentropy',\n            metrics = ['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"earlyStoppingCallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n                                                         patience=EARLY_STOPPING_CRITERIA,\n                                                         verbose= 1 ,\n                                                         restore_best_weights=True\n                                                        )\n\nhistory = model.fit(x = train_generator,\n                    epochs = EPOCHS,\n                    batch_size = BATCH_SIZE,\n                    validation_data = validation_generator , \n                    callbacks= []\n                    )\n\nhistory = pd.DataFrame(history.history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x = px.line(data_frame= history , y= [\"accuracy\" , \"val_accuracy\"] ,markers = True )\nx.update_xaxes(title=\"Number of Epochs\")\nx.update_yaxes(title = \"Accuracy\")\nx.update_layout(showlegend = True,\n    title = {\n        'text': 'Accuracy vs Number of Epochs',\n        'y':0.94,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nx.show()\nx = px.line(data_frame= history , \n            y= [\"loss\" , \"val_loss\"] , markers = True )\nx.update_xaxes(title=\"Number of Epochs\")\nx.update_yaxes(title = \"Loss\")\nx.update_layout(showlegend = True,\n    title = {\n        'text': 'Loss vs Number of Epochs',\n        'y':0.94,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nx.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.evaluate(test_generator)\npreds = model.predict(test_generator)\ny_preds = np.argmax(preds , axis = 1 )\ny_test = np.array(test_generator.labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm_data = confusion_matrix(y_test , y_preds)\ncm = pd.DataFrame(cm_data, columns=CLASS_LABELS, index = CLASS_LABELS)\ncm.index.name = 'Actual'\ncm.columns.name = 'Predicted'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize = (20,10))\nplt.title('Confusion Matrix', fontsize = 20)\nsns.set(font_scale=1.2)\nax = sns.heatmap(cm, cbar=False, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16}, fmt='g')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('model.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"m","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}